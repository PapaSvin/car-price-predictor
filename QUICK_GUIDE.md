# –ö—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –º–æ–¥–µ–ª–∏

## üéØ –ì–ª–∞–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### –ü—Ä–æ–±–ª–µ–º–∞ 1: –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π Dropout (0.4)
**–†–µ—à–µ–Ω–∏–µ:** –°–Ω–∏–∂–µ–Ω –¥–æ 0.2-0.15
- Dropout 0.4 —Å–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–µ–Ω –¥–ª—è –º–∞–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
- –ú–µ—à–∞–µ—Ç –æ–±—É—á–µ–Ω–∏—é, —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç train loss

### –ü—Ä–æ–±–ª–µ–º–∞ 2: –ë–æ–ª—å—à–æ–π Batch Size (64) –ø—Ä–∏ 40 –æ–±—Ä–∞–∑—Ü–∞—Ö
**–†–µ—à–µ–Ω–∏–µ:** –£–º–µ–Ω—å—à–µ–Ω –¥–æ 16
- –ë–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤–µ—Å–æ–≤ –∑–∞ —ç–ø–æ—Ö—É
- –õ—É—á—à–µ –¥–ª—è –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

### –ü—Ä–æ–±–ª–µ–º–∞ 3: –ú–∞–ª—ã–π Learning Rate (0.001)
**–†–µ—à–µ–Ω–∏–µ:** –£–≤–µ–ª–∏—á–µ–Ω –¥–æ 0.003 + –¥–æ–±–∞–≤–ª–µ–Ω scheduler
- –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞—Å—Ç–æ–µ

### –ü—Ä–æ–±–ª–µ–º–∞ 4: MSE Loss —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º
**–†–µ—à–µ–Ω–∏–µ:** –ó–∞–º–µ–Ω–∞ –Ω–∞ Huber Loss
- –£—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º
- –ë–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã

### –ü—Ä–æ–±–ª–µ–º–∞ 5: –ù–µ—Ç Early Stopping
**–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω Early Stopping (patience=50)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
python main_improved.py
```

## üìä –û–∂–∏–¥–∞–µ–º–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ Train Loss

- **–ë—ã–ª–æ:** ~0.15-0.20 (MSE)
- **–°—Ç–∞–Ω–µ—Ç:** ~0.05-0.10 (Huber Loss)
- **–£–ª—É—á—à–µ–Ω–∏–µ:** 2-3x

## üîç –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–¥–µ

```python
# 1. Batch size
train_loader = DataLoader(train_dataset, batch_size=16)  # –±—ã–ª–æ 64

# 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ—â–µ
128‚Üí64‚Üí32‚Üí1  # –±—ã–ª–æ 256‚Üí128‚Üí64‚Üí32‚Üí1

# 3. Dropout –º–µ–Ω—å—à–µ
nn.Dropout(0.2)  # –±—ã–ª–æ 0.4

# 4. LeakyReLU
nn.LeakyReLU(0.1)  # –±—ã–ª–æ nn.ReLU()

# 5. Huber Loss
criterion = nn.HuberLoss(delta=1.0)  # –±—ã–ª–æ nn.MSELoss()

# 6. AdamW + —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π LR
optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=1e-4)

# 7. Scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=20
)

# 8. Gradient Clipping
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# 9. Early Stopping
early_stopping = EarlyStopping(patience=50)
```

## üìà –ß—Ç–æ —Å–º–æ—Ç—Ä–µ—Ç—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

‚úÖ **Train Loss —Å–Ω–∏–∂–∞–µ—Ç—Å—è** - —Ö–æ—Ä–æ—à–∏–π –∑–Ω–∞–∫  
‚úÖ **Test Loss —Å–Ω–∏–∂–∞–µ—Ç—Å—è** - –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞–ª–∏–∑—É–µ—Ç  
‚úÖ **LR —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è** - scheduler —Ä–∞–±–æ—Ç–∞–µ—Ç  
‚ö†Ô∏è **Train Loss << Test Loss** - –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ  

## üí° –î–∞–ª—å–Ω–µ–π—à–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

–ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∏:

1. **–£–≤–µ–ª–∏—á—å—Ç–µ LR:**
   ```python
   optimizer = optim.AdamW(model.parameters(), lr=0.005)
   ```

2. **–£–º–µ–Ω—å—à–∏—Ç–µ dropout –µ—â–µ –±–æ–ª—å—à–µ:**
   ```python
   nn.Dropout(0.1)  # –∏–ª–∏ –¥–∞–∂–µ 0.05
   ```

3. **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ –ø—Ä–æ—â–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:**
   ```python
   64‚Üí32‚Üí1  # –≤—Å–µ–≥–æ 2 —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è
   ```

4. **–ò–∑–º–µ–Ω–∏—Ç–µ delta –≤ Huber Loss:**
   ```python
   criterion = nn.HuberLoss(delta=0.5)  # —Å—Ç—Ä–æ–∂–µ
   ```

## üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã:
- `car_price_predictor_improved_best.pth` - –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å
- `improved_loss_mae_plot.png` - –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
- `improved_confusion_matrix.png` - –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
- `improved_error_distribution.png` - –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫

## ‚ö° –°—Ä–∞–≤–Ω–µ–Ω–∏–µ

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ë—ã–ª–æ | –°—Ç–∞–ª–æ |
|----------|------|-------|
| Batch Size | 64 | **16** ‚úÖ |
| Dropout | 0.4 | **0.2** ‚úÖ |
| LR | 0.001 | **0.003** ‚úÖ |
| Loss | MSE | **Huber** ‚úÖ |
| Optimizer | Adam | **AdamW** ‚úÖ |
| Scheduler | ‚ùå | **‚úÖ** |
| Early Stop | ‚ùå | **‚úÖ** |
| Grad Clip | ‚ùå | **‚úÖ** |

–ß–∏—Ç–∞–π—Ç–µ IMPROVEMENTS.md –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è!
