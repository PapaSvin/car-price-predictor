# ÔøΩ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

–ü—Ä–æ–µ–∫—Ç –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–ª—É–±–æ–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π. –í–∫–ª—é—á–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –¥–æ—Å—Ç–∏–≥–∞—é—â—É—é **MAE $16,640** –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞](#-–æ–ø–∏—Å–∞–Ω–∏–µ-–ø—Ä–æ–µ–∫—Ç–∞)
- [–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏](#-–æ—Å–Ω–æ–≤–Ω—ã–µ-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
- [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è](#-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-—Ä–µ—à–µ–Ω–∏—è)
- [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](#-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
- [–£—Å—Ç–∞–Ω–æ–≤–∫–∞](#-—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
- [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
- [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ](#-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)
- [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
- [–£–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏](#-—É–ª—É—á—à–µ–Ω–∏—è-–º–æ–¥–µ–ª–∏)
- [–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏](#-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ-–¥–µ—Ç–∞–ª–∏)
- [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](#-–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
- [–õ–∏—Ü–µ–Ω–∑–∏—è](#-–ª–∏—Ü–µ–Ω–∑–∏—è)

---

## üéØ –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞

–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è PyTorch –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ **18,400+ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π**. –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ (–º–∞—Ä–∫–∞, –º–æ–¥–µ–ª—å, –≥–æ–¥, –ø—Ä–æ–±–µ–≥, —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –æ–ø—Ü–∏–∏) –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ä—ã–Ω–æ—á–Ω—É—é —Ü–µ–Ω—É —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é.

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| **–î–∞—Ç–∞—Å–µ—Ç** | 18,400 –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π |
| **Test MAE** | $16,640 |
| **Best Test Loss** | 0.0814 (Huber Loss) |
| **F1 Score** | 0.4171 |
| **Training Time** | ~500 —ç–ø–æ—Ö (Early Stopping) |

---

## ‚ú® –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω
- –¢–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
- –£—á–µ—Ç –±–æ–ª–µ–µ 20 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ü–µ–Ω–æ–≤—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (Very Low, Low, Medium, High, Very High)

### üß† –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π** –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è train loss
- Huber Loss –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ –≤—ã–±—Ä–æ—Å–∞–º
- LeakyReLU –∞–∫—Ç–∏–≤–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
- Adaptive Learning Rate —Å scheduler
- Early Stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

### üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑
- –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è (Loss, MAE)
- –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä

### üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

| ‚Ññ | –ü—Ä–æ–±–ª–µ–º–∞ | –ë—ã–ª–æ | –°—Ç–∞–ª–æ | –≠—Ñ—Ñ–µ–∫—Ç |
|---|----------|------|-------|--------|
| 1 | Batch Size | 64 | **16** | 4x –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π |
| 2 | Dropout | 0.4 | **0.2-0.15** | –õ—É—á—à–µ –æ–±—É—á–µ–Ω–∏–µ |
| 3 | Learning Rate | 0.001 | **0.003 + scheduler** | –ë—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å |
| 4 | –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ | 4 —Å–ª–æ—è | **3 —Å–ª–æ—è** | –ú–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è |
| 5 | Loss Function | MSE | **Huber Loss** | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º |
| 6 | Optimizer | Adam | **AdamW** | –õ—É—á—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |
| 7 | Activation | ReLU | **LeakyReLU** | –ù–µ—Ç dying neurons |
| 8 | LR Scheduler | ‚ùå | **ReduceLROnPlateau** | –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å |
| 9 | Early Stopping | ‚ùå | **Patience=50** | –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —ç–ø–æ—Ö–∏ |
| 10 | Gradient Clipping | ‚ùå | **max_norm=1.0** | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å |

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

### Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

```
–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)
    ‚Üì
Feature Engineering (Age, LogMileage)
    ‚Üì
Encoding (LabelEncoder, MultiLabelBinarizer)
    ‚Üì
Normalization (StandardScaler)
    ‚Üì
Train/Test Split (80/20)
    ‚Üì
DataLoader (Batch Size: 32)
    ‚Üì
Neural Network
    ‚Üì
Predictions
```

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

**–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (ImprovedCarPricePredictor):**

```
Input (20 features)
    ‚Üì
Linear(20 ‚Üí 128) ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.2)
    ‚Üì
Linear(128 ‚Üí 64) ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.2)
    ‚Üì
Linear(64 ‚Üí 32) ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.15)
    ‚Üì
Linear(32 ‚Üí 1)
    ‚Üì
Output (Predicted Price)
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- **3 —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è** (–≤–º–µ—Å—Ç–æ 4 –≤ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏)
- **LeakyReLU** –≤–º–µ—Å—Ç–æ ReLU (—Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É dying neurons)
- **–ú–µ–Ω—å—à–∏–π Dropout** (0.2-0.15 –≤–º–µ—Å—Ç–æ 0.4)
- **Kaiming –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è** –≤–µ—Å–æ–≤
- **Huber Loss** –≤–º–µ—Å—Ç–æ MSE

---

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏

```
Best Test Loss:    0.0814 (Huber Loss)
Final Test MAE:    $16,640.25
F1 Score:          0.4171
Train MAE:         $19,964.45
```

### –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

| –ê–≤—Ç–æ–º–æ–±–∏–ª—å | –ì–æ–¥ | –ü—Ä–æ–±–µ–≥ | –°–æ—Å—Ç–æ—è–Ω–∏–µ | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ |
|-----------|-----|--------|-----------|-------------------|
| Honda Civic | 2024 | 1,242 –∫–º | New | **$50,610** |
| Honda Civic | 2015 | 75,000 –∫–º | Used | **$12,197** |
| Honda Civic | 2004 | 150,000 –∫–º | Used | **$7,962** |

**–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –Ω–æ–≤—ã–º –∏ —Å—Ç–∞—Ä—ã–º –∞–≤—Ç–æ:** $42,648 ‚úÖ

---

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.8+
- CUDA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è GPU)

### –®–∞–≥ 1: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone https://github.com/yourusername/car-price-predictor.git
cd car-price-predictor
```

### –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

–§–∞–π–ª `requirements.txt` –≤–∫–ª—é—á–∞–µ—Ç:
- `torch>=2.0.0` - PyTorch
- `numpy>=1.24.0` - –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
- `pandas>=2.0.0` - –†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
- `scikit-learn>=1.3.0` - Preprocessing –∏ –º–µ—Ç—Ä–∏–∫–∏
- `matplotlib>=3.7.0` - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- `seaborn>=0.12.0` - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

---

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1Ô∏è‚É£ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
python main_improved.py
```

**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç:**
- ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ preprocessing –¥–∞–Ω–Ω—ã—Ö (18,400 –æ–±—Ä–∞–∑—Ü–æ–≤)
- ‚úÖ –û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–æ 500 —ç–ø–æ—Ö
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Early Stopping –ø—Ä–∏ –∑–∞—Å—Ç–æ–µ
- ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
- ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**–í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å:**
```
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu
–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ 18400 –æ–±—Ä–∞–∑—Ü–∞—Ö...
–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 32, Learning rate: 0.003
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –∑–∞ —ç–ø–æ—Ö—É: Train=575, Test=144

Epoch [10/500], LR: 0.003000, Train Loss: 0.2341, Test Loss: 0.1892, ...
Epoch [20/500], LR: 0.003000, Train Loss: 0.1654, Test Loss: 0.1423, ...
...
Epoch [490/500], LR: 0.000006, Train Loss: 0.1175, Test Loss: 0.0839, ...
Early stopping –Ω–∞ —ç–ø–æ—Ö–µ 500

=== –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===
Best Test Loss: 0.0814
Final Test MAE: $16640.25
F1 Score: 0.4171
```

**–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:**
- `car_price_predictor_improved.pth` - —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
- `car_price_predictor_improved_best.pth` - –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å
- `improved_loss_mae_plot.png` - –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
- `improved_confusion_matrix.png` - –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
- `improved_error_distribution.png` - –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

### 2Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

```bash
python predictor.py
```

**–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:**
```python
# –¢–ï–°–¢ 1: Honda Civic 2024, –Ω–æ–≤—ã–π, –º–∞–ª—ã–π –ø—Ä–æ–±–µ–≥
Predicted Price: $50,610.14
Price Class: Very Low

# –¢–ï–°–¢ 2: Honda Civic 2004, —Å—Ç–∞—Ä—ã–π, –±–æ–ª—å—à–æ–π –ø—Ä–æ–±–µ–≥
Predicted Price: $7,961.70
Price Class: Very Low

# –¢–ï–°–¢ 3: Honda Civic 2015, —Å—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç
Predicted Price: $12,196.53
Price Class: Very Low
```

### 3Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π

```bash
python visualize_improvements.py
```

**–°–æ–∑–¥–∞—Å—Ç –≥—Ä–∞—Ñ–∏–∫–∏:**
- `architecture_comparison.png` - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –∏ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- `hyperparameters_comparison.png` - –¢–∞–±–ª–∏—Ü–∞ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
- `expected_loss_improvement.png` - –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ loss

---

## üíª –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –û–±—É—á–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

```python
# –í main_improved.py –∏–∑–º–µ–Ω–∏—Ç–µ:
num_epochs = 1000           # –ú–∞–∫—Å–∏–º—É–º —ç–ø–æ—Ö
batch_size = 64             # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
lr = 0.005                  # Learning rate
patience = 100              # Early stopping patience
```

### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è —Å–≤–æ–µ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è

```python
import pandas as pd
from predictor import predict_price, model, scaler_features, scaler_price, label_encoders, mlb, device, make_model_class_dict

# –í–∞—à –∞–≤—Ç–æ–º–æ–±–∏–ª—å
my_car = pd.DataFrame({
    'Car Make': ['Toyota'],
    'Car Model': ['Camry'],
    'Year': [2020],
    'Mileage': [45000],
    'Fuel Type': ['Hybrid'],
    'Color': ['Silver'],
    'Transmission': ['Automatic'],
    'Options/Features': ['GPS, Bluetooth, Backup Camera'],
    'Condition': ['Like New'],
    'Accident': ['No']
})

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
price, price_class = predict_price(
    new_data=my_car.copy(),
    model=model,
    scaler_features=scaler_features,
    scaler_price=scaler_price,
    label_encoders=label_encoders,
    mlb=mlb,
    device=device,
    make_model_class_dict=make_model_class_dict
)

print(f'Predicted Price: ${price:.2f}')
print(f'Price Class: {price_class}')
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
timo6/
‚îÇ
‚îú‚îÄ‚îÄ ÔøΩ –û–°–ù–û–í–ù–´–ï –°–ö–†–ò–ü–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ main_improved.py              # ‚≠ê –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–ò–°–ü–û–õ–¨–ó–£–ô–¢–ï –≠–¢–û–¢!)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                       # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py                  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω –¥–ª—è –Ω–æ–≤—ã—Ö –∞–≤—Ç–æ
‚îÇ   ‚îú‚îÄ‚îÄ data_builder.py               # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ visualize_improvements.py     # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π
‚îÇ
‚îú‚îÄ‚îÄ üìö –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø
‚îÇ   ‚îú‚îÄ‚îÄ README.md                     # ‚≠ê –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª (–í–´ –ó–î–ï–°–¨)
‚îÇ   ‚îú‚îÄ‚îÄ SUMMARY.md                    # –ü–æ–ª–Ω–æ–µ —Ä–µ–∑—é–º–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ IMPROVEMENTS.md               # –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ 10 —É–ª—É—á—à–µ–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ QUICK_GUIDE.md                # –ë—ã—Å—Ç—Ä–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ –ü–ê–ú–Ø–¢–ö–ê.txt                   # –ö—Ä–∞—Ç–∫–∞—è –ø–∞–º—è—Ç–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt              # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îÇ
‚îú‚îÄ‚îÄ ÔøΩ –î–ê–ù–ù–´–ï
‚îÇ   ‚îú‚îÄ‚îÄ Updated_Car_Sales_Data.csv                      # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îú‚îÄ‚îÄ Updated_Car_Sales_Data_with_Classes.csv         # –° –∫–ª–∞—Å—Å–∞–º–∏ —Ü–µ–Ω
‚îÇ   ‚îî‚îÄ‚îÄ Updated_Car_Sales_Data_with_Classes_prepared.csv # –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ
‚îú‚îÄ‚îÄ üß† –ú–û–î–ï–õ–ò –ò –û–ë–™–ï–ö–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ car_price_predictor_improved.pth       # ‚≠ê –§–∏–Ω–∞–ª—å–Ω–∞—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
‚îÇ   ‚îú‚îÄ‚îÄ car_price_predictor_improved_best.pth  # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (–ø–æ validation)
‚îÇ   ‚îú‚îÄ‚îÄ car_price_predictor_with_classes.pth   # –°—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å
‚îÇ   ‚îú‚îÄ‚îÄ scaler_features.pkl                    # Scaler –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ scaler_price.pkl                       # Scaler –¥–ª—è —Ü–µ–Ω
‚îÇ   ‚îú‚îÄ‚îÄ label_encoders.pkl                     # Encoders –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ mlb.pkl                                # MultiLabelBinarizer
‚îÇ   ‚îî‚îÄ‚îÄ make_model_class_dict.pkl              # –°–ª–æ–≤–∞—Ä—å –º–∞—Ä–æ–∫/–º–æ–¥–µ–ª–µ–π
‚îÇ
‚îú‚îÄ‚îÄ üìä –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò
‚îÇ   ‚îú‚îÄ‚îÄ improved_loss_mae_plot.png             # ‚≠ê –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è (—É–ª—É—á—à–µ–Ω–Ω–∞—è)
‚îÇ   ‚îú‚îÄ‚îÄ improved_confusion_matrix.png          # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (—É–ª—É—á—à–µ–Ω–Ω–∞—è)
‚îÇ   ‚îú‚îÄ‚îÄ improved_error_distribution.png        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ (—É–ª—É—á—à–µ–Ω–Ω–∞—è)
‚îÇ   ‚îú‚îÄ‚îÄ architecture_comparison.png            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameters_comparison.png         # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ expected_loss_improvement.png          # –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ loss_plot.png                          # –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ mae_plot.png                           # MAE —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png                   # –°—Ç–∞—Ä–∞—è confusion matrix
‚îÇ   ‚îî‚îÄ‚îÄ error_distribution.png                 # –°—Ç–∞—Ä–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
‚îÇ
‚îî‚îÄ‚îÄ ÔøΩÔ∏è –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û
    ‚îú‚îÄ‚îÄ car_price_results/                     # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã K-Fold CV
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model_fold_0.pth
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model_fold_1.pth
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model_fold_2.pth
    ‚îÇ   ‚îú‚îÄ‚îÄ best_model_fold_3.pth
    ‚îÇ   ‚îî‚îÄ‚îÄ best_model_fold_4.pth
    ‚îî‚îÄ‚îÄ catboost_info/                         # –õ–æ–≥–∏ CatBoost (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è)
```

### üîë –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã

1. **README.md** (—ç—Ç–æ—Ç —Ñ–∞–π–ª) - –æ–±—â–∏–π –æ–±–∑–æ—Ä
2. **main_improved.py** - –∑–∞–ø—É—Å—Ç–∏—Ç–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
3. **predictor.py** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
4. **SUMMARY.md** - –ø–æ–ª–Ω–æ–µ —Ä–µ–∑—é–º–µ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
5. **requirements.txt** - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

---

## ÔøΩ –£–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

–ü—Ä–æ–≤–µ–¥–µ–Ω–∞ **–ø–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –í—ã—è–≤–ª–µ–Ω–æ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ **10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º**.

### üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –ë—ã–ª–æ vs –°—Ç–∞–ª–æ

| ‚Ññ | –ü–∞—Ä–∞–º–µ—Ç—Ä | –ë—ã–ª–æ | –°—Ç–∞–ª–æ | –≠—Ñ—Ñ–µ–∫—Ç |
|---|----------|------|-------|--------|
| 1 | **Batch Size** | 64 | **32** | 4x –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –Ω–∞ —ç–ø–æ—Ö—É |
| 2 | **Dropout** | 0.4 | **0.2-0.15** | –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ª—É—á—à–µ –æ–±—É—á–∞—Ç—å—Å—è |
| 3 | **Learning Rate** | 0.001 | **0.003 + scheduler** | –ë—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å + —Ç–æ—á–Ω–æ—Å—Ç—å |
| 4 | **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** | 256‚Üí128‚Üí64‚Üí32 | **128‚Üí64‚Üí32** | –ú–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è |
| 5 | **Loss Function** | MSE | **Huber Loss** | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º |
| 6 | **Optimizer** | Adam | **AdamW** | –õ—É—á—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |
| 7 | **Activation** | ReLU | **LeakyReLU** | –ù–µ—Ç dying neurons |
| 8 | **LR Scheduler** | ‚ùå –ù–µ—Ç | **‚úÖ ReduceLROnPlateau** | –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å |
| 9 | **Early Stopping** | ‚ùå –ù–µ—Ç | **‚úÖ Patience=50** | –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ —ç–ø–æ—Ö–∏ |
| 10 | **Gradient Clipping** | ‚ùå –ù–µ—Ç | **‚úÖ max_norm=1.0** | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å |

### üéØ –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π

<details>
<summary><b>1. –£–º–µ–Ω—å—à–µ–Ω–∏–µ Batch Size (64 ‚Üí 32)</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–∏ 18,400 –æ–±—Ä–∞–∑—Ü–∞—Ö batch_size=64 –¥–∞–µ—Ç ~288 –±–∞—Ç—á–µ–π –∑–∞ —ç–ø–æ—Ö—É. –î–ª—è –ª—É—á—à–µ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π.

**–†–µ—à–µ–Ω–∏–µ:** Batch_size=32 ‚Üí ~575 –±–∞—Ç—á–µ–π ‚Üí 2x –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤–µ—Å–æ–≤

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ë—ã—Å—Ç—Ä–µ–µ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –ª—É—á—à–µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è
</details>

<details>
<summary><b>2. –°–Ω–∏–∂–µ–Ω–∏–µ Dropout (0.4 ‚Üí 0.2-0.15)</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** Dropout 0.4 –æ—Ç–∫–ª—é—á–∞–µ—Ç 40% –Ω–µ–π—Ä–æ–Ω–æ–≤ ‚Üí –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –∑–∞—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∞, –Ω–µ –º–æ–∂–µ—Ç –æ–±—É—á–∏—Ç—å—Å—è

**–†–µ—à–µ–Ω–∏–µ:** Dropout 0.2-0.15 ‚Üí –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π –∏ –æ–±—É—á–µ–Ω–∏–µ–º

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Train loss —Å–Ω–∏–∂–∞–µ—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ, –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ
</details>

<details>
<summary><b>3. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ Learning Rate (0.001 ‚Üí 0.003)</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** LR 0.001 —Å–ª–∏—à–∫–æ–º –º–∞–ª ‚Üí –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å

**–†–µ—à–µ–Ω–∏–µ:** LR 0.003 (3x –±–æ–ª—å—à–µ) + ReduceLROnPlateau scheduler

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –∑–∞—Ç–µ–º —Ç–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
</details>

<details>
<summary><b>4. –£–ø—Ä–æ—â–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (4 —Å–ª–æ—è ‚Üí 3 —Å–ª–æ—è)</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** –ì–ª—É–±–æ–∫–∞—è —Å–µ—Ç—å (256‚Üí128‚Üí64‚Üí32) —Å–∫–ª–æ–Ω–Ω–∞ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é

**–†–µ—à–µ–Ω–∏–µ:** –£–ø—Ä–æ—â–µ–Ω–∞ –¥–æ 128‚Üí64‚Üí32 (3 —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –õ—É—á—à–µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è, –º–µ–Ω—å—à–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
</details>

<details>
<summary><b>5. Huber Loss –≤–º–µ—Å—Ç–æ MSE</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** MSE = error¬≤ ‚Üí –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏ –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç –≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞—Ö

**–†–µ—à–µ–Ω–∏–µ:** Huber Loss = MSE –¥–ª—è –º–∞–ª—ã—Ö –æ—à–∏–±–æ–∫ + MAE –¥–ª—è –±–æ–ª—å—à–∏—Ö

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º, –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
</details>

<details>
<summary><b>6. AdamW –≤–º–µ—Å—Ç–æ Adam</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** Adam –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç weight decay

**–†–µ—à–µ–Ω–∏–µ:** AdamW + weight_decay=1e-4 (10x —É–≤–µ–ª–∏—á–µ–Ω–∏–µ)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –õ—É—á—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è, –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
</details>

<details>
<summary><b>7. LeakyReLU –≤–º–µ—Å—Ç–æ ReLU</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** ReLU –º–æ–∂–µ—Ç "—É–º–∏—Ä–∞—Ç—å" (–≥—Ä–∞–¥–∏–µ–Ω—Ç=0 –¥–ª—è x<0)

**–†–µ—à–µ–Ω–∏–µ:** LeakyReLU(0.1) ‚Üí –Ω–µ–±–æ–ª—å—à–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –õ—É—á—à–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤, –Ω–µ—Ç –º–µ—Ä—Ç–≤—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤
</details>

<details>
<summary><b>8. Learning Rate Scheduler</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LR –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –Ω–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–∞—Ö –æ–±—É—á–µ–Ω–∏—è

**–†–µ—à–µ–Ω–∏–µ:** ReduceLROnPlateau (factor=0.5, patience=20)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
</details>

<details>
<summary><b>9. Early Stopping</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é

**–†–µ—à–µ–Ω–∏–µ:** Early Stopping —Å patience=50

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–∫–µ
</details>

<details>
<summary><b>10. Gradient Clipping</b></summary>

**–ü—Ä–æ–±–ª–µ–º–∞:** –í–æ–∑–º–æ–∂–µ–Ω –≤–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –±–æ–ª—å—à–æ–º LR

**–†–µ—à–µ–Ω–∏–µ:** torch.nn.utils.clip_grad_norm_(max_norm=1.0)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —Å–∫–∞—á–∫–æ–≤ loss
</details>

–ü–æ–¥—Ä–æ–±–Ω–µ–µ —á–∏—Ç–∞–π—Ç–µ –≤ **[IMPROVEMENTS.md](IMPROVEMENTS.md)**

---

## üî¨ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### –í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (20 features)

**–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ:**
- Car Make (–º–∞—Ä–∫–∞)
- Car Model (–º–æ–¥–µ–ª—å)
- Fuel Type (—Ç–∏–ø —Ç–æ–ø–ª–∏–≤–∞)
- Color (—Ü–≤–µ—Ç)
- Transmission (–∫–æ—Ä–æ–±–∫–∞ –ø–µ—Ä–µ–¥–∞—á)
- Condition (—Å–æ—Å—Ç–æ—è–Ω–∏–µ)
- Accident (–±—ã–ª–∞ –ª–∏ –∞–≤–∞—Ä–∏—è)
- Price_Class (–∫–ª–∞—Å—Å —Ü–µ–Ω—ã)

**–ß–∏—Å–ª–æ–≤—ã–µ:**
- Year (–≥–æ–¥ –≤—ã–ø—É—Å–∫–∞)
- Mileage (–ø—Ä–æ–±–µ–≥)
- Age (–≤–æ–∑—Ä–∞—Å—Ç = 2025 - Year)
- LogMileage (log(1 + Mileage))

**–û–ø—Ü–∏–∏ (MultiLabelBinarizer):**
- Backup Camera, Bluetooth, GPS, Heated Seats, Leather Seats, Navigation, Remote Start, Sunroof

### Preprocessing Pipeline

1. **Feature Engineering:**
   - Age = 2025 - Year
   - LogMileage = log(1 + Mileage)

2. **Encoding:**
   - LabelEncoder –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   - MultiLabelBinarizer –¥–ª—è –æ–ø—Ü–∏–π (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä)

3. **Normalization:**
   - StandardScaler –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   - StandardScaler –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (Price)

4. **Train/Test Split:**
   - 80% train (14,720 –æ–±—Ä–∞–∑—Ü–æ–≤)
   - 20% test (3,680 –æ–±—Ä–∞–∑—Ü–æ–≤)

### –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

```python
# –ú–æ–¥–µ–ª—å
input_size = 20
hidden_layers = [128, 64, 32]
dropout = [0.2, 0.2, 0.15]
activation = LeakyReLU(0.1)

# –û–±—É—á–µ–Ω–∏–µ
batch_size = 32
learning_rate = 0.003
weight_decay = 1e-4
max_epochs = 500
early_stopping_patience = 50

# Loss & Optimizer
criterion = HuberLoss(delta=1.0)
optimizer = AdamW
scheduler = ReduceLROnPlateau(factor=0.5, patience=20)

# –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è
gradient_clipping = 1.0
weight_init = Kaiming/He
```

### Hardware Requirements

**CPU Mode (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):**
- RAM: 8GB+
- Training time: ~2-3 –º–∏–Ω—É—Ç—ã –∑–∞ 100 —ç–ø–æ—Ö

**GPU Mode (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
- CUDA compatible GPU
- VRAM: 2GB+
- Training time: ~30-60 —Å–µ–∫—É–Ω–¥ –∑–∞ 100 —ç–ø–æ—Ö

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### üìñ –§–∞–π–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

1. **[README.md](README.md)** (—ç—Ç–æ—Ç —Ñ–∞–π–ª) - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ø—Ä–æ–µ–∫—Ç—É
2. **[SUMMARY.md](SUMMARY.md)** - –†–µ–∑—é–º–µ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **[IMPROVEMENTS.md](IMPROVEMENTS.md)** - –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ 10 —É–ª—É—á—à–µ–Ω–∏–π
4. **[QUICK_GUIDE.md](QUICK_GUIDE.md)** - –ë—ã—Å—Ç—Ä–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö
5. **[–ü–ê–ú–Ø–¢–ö–ê.txt](–ü–ê–ú–Ø–¢–ö–ê.txt)** - –ö—Ä–∞—Ç–∫–∞—è –ø–∞–º—è—Ç–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º

### üéì –° —á–µ–≥–æ –Ω–∞—á–∞—Ç—å?

**–ù–æ–≤–∏—á–∫–∏:**
1. –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ **README.md** (–≤—ã –∑–¥–µ—Å—å)
2. –ò–∑—É—á–∏—Ç–µ **QUICK_GUIDE.md**
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ `python main_improved.py`

**–û–ø—ã—Ç–Ω—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏:**
1. –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ **SUMMARY.md**
2. –ò–∑—É—á–∏—Ç–µ **IMPROVEMENTS.md**
3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

**–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ ML:**
1. –ò–∑—É—á–∏—Ç–µ **IMPROVEMENTS.md**
2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
3. –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ –∑–∞–¥–∞—á–∏

## üîç –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

```python
# –ë–´–õ–û:
batch_size = 64
dropout = 0.4
lr = 0.001
weight_decay = 1e-5

# –°–¢–ê–õ–û:
batch_size = 16          # 4x –º–µ–Ω—å—à–µ ‚Üí –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
dropout = 0.2-0.15       # 2x –º–µ–Ω—å—à–µ ‚Üí –ª—É—á—à–µ –æ–±—É—á–µ–Ω–∏–µ
lr = 0.003               # 3x –±–æ–ª—å—à–µ ‚Üí –±—ã—Å—Ç—Ä–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
weight_decay = 1e-4      # 10x –±–æ–ª—å—à–µ ‚Üí –ª—É—á—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
```

### 2. –£–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

```python
# –ë–´–õ–û:
Linear(input, 256) ‚Üí ReLU ‚Üí BatchNorm ‚Üí Dropout(0.4)
Linear(256, 128)   ‚Üí ReLU ‚Üí BatchNorm ‚Üí Dropout(0.4)
Linear(128, 64)    ‚Üí ReLU ‚Üí BatchNorm ‚Üí Dropout(0.4)
Linear(64, 32)     ‚Üí ReLU ‚Üí BatchNorm ‚Üí Dropout(0.4)
Linear(32, 1)

# –°–¢–ê–õ–û:
Linear(input, 128) ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.2)
Linear(128, 64)    ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.2)
Linear(64, 32)     ‚Üí LeakyReLU(0.1) ‚Üí BatchNorm ‚Üí Dropout(0.15)
Linear(32, 1)
```

### 3. –ù–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

```python
# Loss Function
criterion = nn.HuberLoss(delta=1.0)  # –í–º–µ—Å—Ç–æ nn.MSELoss()

# Optimizer
optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=1e-4)

# Learning Rate Scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=20
)

# Early Stopping
early_stopping = EarlyStopping(patience=50, min_delta=1e-5)

# Gradient Clipping
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# Weight Initialization
nn.init.kaiming_normal_(weight, mode='fan_out', nonlinearity='leaky_relu')
```

## üí° –ü–æ—á–µ–º—É —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?

### –ú–µ–Ω—å—à–∏–π Batch Size (16 –≤–º–µ—Å—Ç–æ 64)
- **–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–∏ 40 –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö batch_size=64 ‚Üí –≤—Å–µ–≥–æ ~1 –±–∞—Ç—á –∑–∞ —ç–ø–æ—Ö—É
- **–†–µ—à–µ–Ω–∏–µ:** batch_size=16 ‚Üí 2-3 –±–∞—Ç—á–∞ ‚Üí 2-3x –±–æ–ª—å—à–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤–µ—Å–æ–≤
- **–≠—Ñ—Ñ–µ–∫—Ç:** –ë—ã—Å—Ç—Ä–µ–µ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å, –±–æ–ª—å—à–µ "—à—É–º–∞" –ø–æ–º–æ–≥–∞–µ—Ç –≤—ã–π—Ç–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤

### –ú–µ–Ω—å—à–∏–π Dropout (0.2 –≤–º–µ—Å—Ç–æ 0.4)
- **–ü—Ä–æ–±–ª–µ–º–∞:** Dropout 0.4 –æ—Ç–∫–ª—é—á–∞–µ—Ç 40% –Ω–µ–π—Ä–æ–Ω–æ–≤ ‚Üí –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –∑–∞—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∞
- **–†–µ—à–µ–Ω–∏–µ:** Dropout 0.2-0.15 ‚Üí –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π –∏ –æ–±—É—á–µ–Ω–∏–µ–º
- **–≠—Ñ—Ñ–µ–∫—Ç:** –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è, –Ω–æ –Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è

### –ë–æ–ª—å—à–∏–π Learning Rate (0.003 –≤–º–µ—Å—Ç–æ 0.001)
- **–ü—Ä–æ–±–ª–µ–º–∞:** LR 0.001 —Å–ª–∏—à–∫–æ–º –º–∞–ª ‚Üí –º–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- **–†–µ—à–µ–Ω–∏–µ:** LR 0.003 + scheduler ‚Üí –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç, –∑–∞—Ç–µ–º —Ç–æ—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
- **–≠—Ñ—Ñ–µ–∫—Ç:** –ë—ã—Å—Ç—Ä–æ –¥–æ—Å—Ç–∏–≥–∞–µ–º –æ–±–ª–∞—Å—Ç–∏ –º–∏–Ω–∏–º—É–º–∞, scheduler —É—Ç–æ—á–Ω—è–µ—Ç

### Huber Loss –≤–º–µ—Å—Ç–æ MSE
- **–ü—Ä–æ–±–ª–µ–º–∞:** MSE = error¬≤ ‚Üí –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏ –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç –≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞—Ö
- **–†–µ—à–µ–Ω–∏–µ:** Huber = MSE –¥–ª—è –º–∞–ª—ã—Ö + MAE –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ—à–∏–±–æ–∫
- **–≠—Ñ—Ñ–µ–∫—Ç:** –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º, –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã

### –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **–ü—Ä–æ–±–ª–µ–º–∞:** 4 —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è (256‚Üí128‚Üí64‚Üí32) –¥–ª—è ~50 –æ–±—Ä–∞–∑—Ü–æ–≤ ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- **–†–µ—à–µ–Ω–∏–µ:** 3 —Å–ª–æ—è (128‚Üí64‚Üí32) ‚Üí –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–≠—Ñ—Ñ–µ–∫—Ç:** –õ—É—á—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è, –º–µ–Ω—å—à–µ —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞–∫–∏ ‚úÖ
- Train Loss –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç—Å—è
- Test Loss —Å–Ω–∏–∂–∞–µ—Ç—Å—è –≤–º–µ—Å—Ç–µ —Å Train Loss
- –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Train –∏ Test Loss < 30%
- Learning Rate —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
- MAE –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö —Å–Ω–∏–∂–∞–µ—Ç—Å—è

### –ü–ª–æ—Ö–∏–µ –∑–Ω–∞–∫–∏ ‚ö†Ô∏è
- Train Loss << Test Loss ‚Üí –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (—É–≤–µ–ª–∏—á—å—Ç–µ dropout)
- Loss –Ω–µ —Å–Ω–∏–∂–∞–µ—Ç—Å—è ‚Üí –£–≤–µ–ª–∏—á—å—Ç–µ LR –∏–ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª—å
- Loss = NaN ‚Üí –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π LR (—É–º–µ–Ω—å—à–∏—Ç–µ)
- Test Loss —Ä–∞—Å—Ç–µ—Ç ‚Üí –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ (early stopping –ø–æ–º–æ–∂–µ—Ç)

## üéì –î–∞–ª—å–Ω–µ–π—à–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

–ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã:

### 1. –ï—â–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ
```python
lr = 0.005                  # –ï—â–µ –≤—ã—à–µ
dropout = 0.1               # –ï—â–µ –º–µ–Ω—å—à–µ
```

### 2. –ï—â–µ –ø—Ä–æ—â–µ
```python
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: 64‚Üí32‚Üí1
self.model = nn.Sequential(
    nn.Linear(input_size, 64),
    nn.LeakyReLU(0.1),
    nn.Dropout(0.1),
    nn.Linear(64, 32),
    nn.LeakyReLU(0.1),
    nn.Linear(32, 1)
)
```

### 3. –î—Ä—É–≥–∏–µ loss functions
```python
criterion = nn.HuberLoss(delta=0.5)     # –°—Ç—Ä–æ–∂–µ
criterion = nn.SmoothL1Loss()           # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
criterion = nn.L1Loss()                 # MAE
```

---

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é—Ç—Å—è –ª—é–±—ã–µ —É–ª—É—á—à–µ–Ω–∏—è! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞:

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit –∏–∑–º–µ–Ω–µ–Ω–∏—è (`git commit -m 'Add some AmazingFeature'`)
4. Push –≤ branch (`git push origin feature/AmazingFeature`)
5. –û—Ç–∫—Ä–æ–π—Ç–µ Pull Request

### –ò–¥–µ–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π

- [ ] –î–æ–±–∞–≤–∏—Ç—å K-Fold Cross-Validation
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Ensemble –º–µ—Ç–æ–¥—ã (Stacking, Blending)
- [ ] –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ feature engineering
- [ ] –°–æ–∑–¥–∞—Ç—å Web –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (Flask/FastAPI)
- [ ] –î–æ–±–∞–≤–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç –≤ ONNX –¥–ª—è production
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å SHAP –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
- [ ] –î–æ–±–∞–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (Optuna)

---

## ÔøΩ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

### –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è

![Training Loss](improved_loss_mae_plot.png)

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É —Å–Ω–∏–∂–µ–Ω–∏—è loss –∏ MAE –Ω–∞ train –∏ test –Ω–∞–±–æ—Ä–∞—Ö.

### –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫

![Confusion Matrix](improved_confusion_matrix.png)

–ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ —Ü–µ–Ω–æ–≤—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫

![Error Distribution](improved_error_distribution.png)

–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ scatter plot true vs predicted.

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä

![Architecture Comparison](architecture_comparison.png)

–í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏.

---

## üêõ –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### GPU Memory Error

**–ü—Ä–æ–±–ª–µ–º–∞:** `CUDA error: out of memory` –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ GPU

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –í main_improved.py –∏–ª–∏ predictor.py –∏–∑–º–µ–Ω–∏—Ç–µ:
device = torch.device("cpu")  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU
```

### –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–∞—Ä–æ–∫

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–¥–∫–∏–µ –º–∞—Ä–∫–∏/–º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

**–†–µ—à–µ–Ω–∏–µ:** –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç fallback –ª–æ–≥–∏–∫—É –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –º–∞—Ä–æ–∫

---

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –≤–æ–ø—Ä–æ—Å—ã:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ **[QUICK_GUIDE.md](QUICK_GUIDE.md)**
2. –ò–∑—É—á–∏—Ç–µ **[SUMMARY.md](SUMMARY.md)**
3. –û—Ç–∫—Ä–æ–π—Ç–µ Issue –Ω–∞ GitHub
4. –ù–∞–ø–∏—à–∏—Ç–µ –∞–≤—Ç–æ—Ä—É

---

## üìù Changelog

### Version 2.0 (Improved) - –¢–µ–∫—É—â–∞—è

‚úÖ **10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π:**
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –£–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ scheduler –∏ early stopping
- Huber Loss –≤–º–µ—Å—Ç–æ MSE
- LeakyReLU –≤–º–µ—Å—Ç–æ ReLU

üìà **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- Test MAE: $16,640
- Best Test Loss: 0.0814
- F1 Score: 0.4171

### Version 1.0 (Original)

- –ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 256‚Üí128‚Üí64‚Üí32
- MSE Loss
- –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- Train Loss: ~0.15-0.20

---

## üèÜ –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- PyTorch team –∑–∞ –æ—Ç–ª–∏—á–Ω—ã–π framework
- Scikit-learn –∑–∞ preprocessing –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
- Matplotlib/Seaborn –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
- –°–æ–æ–±—â–µ—Å—Ç–≤–æ ML –∑–∞ best practices

---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT. –°–º. —Ñ–∞–π–ª `LICENSE` –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.

---

## üì¨ –ö–æ–Ω—Ç–∞–∫—Ç—ã

**–ê–≤—Ç–æ—Ä:** –í–∞—à–µ –∏–º—è  
**Email:** your.email@example.com  
**GitHub:** [@yourusername](https://github.com/yourusername)  
**LinkedIn:** [Your LinkedIn](https://linkedin.com/in/yourprofile)

---

## ‚≠ê Star History

–ï—Å–ª–∏ —ç—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –±—ã–ª –ø–æ–ª–µ–∑–µ–Ω, –ø–æ—Å—Ç–∞–≤—å—Ç–µ –∑–≤–µ–∑–¥—É! ‚≠ê

---

<div align="center">

**–°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è –∏ PyTorch**

[‚¨Ü –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞—á–∞–ª—É](#-–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ-—Ü–µ–Ω-–∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π-—Å-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º-–Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö-—Å–µ—Ç–µ–π)

</div>

## üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

–°–æ–∑–¥–∞–Ω—ã 3 –≥—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:

1. **architecture_comparison.png** - –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –∏ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
2. **hyperparameters_comparison.png** - –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
3. **expected_loss_improvement.png** - –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ loss –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

## ‚ú® –ò—Ç–æ–≥–∏

### –ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:
- ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Ñ–∞–π–ª—ã (`main.py`, `predictor.py`, `data_builder.py`)
- ‚úÖ –í—ã—è–≤–ª–µ–Ω–æ 10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º
- ‚úÖ –°–æ–∑–¥–∞–Ω —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–¥ (`main_improved.py`)
- ‚úÖ –ù–∞–ø–∏—Å–∞–Ω–∞ –ø–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (5 —Ñ–∞–π–ª–æ–≤)
- ‚úÖ –°–æ–∑–¥–∞–Ω—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (3 –≥—Ä–∞—Ñ–∏–∫–∞)

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
- üéØ **Train Loss —Å–Ω–∏–∑–∏—Ç—Å—è –≤ 2-3 —Ä–∞–∑–∞** (—Å ~0.15-0.20 –¥–æ ~0.05-0.10)
- ‚ö° –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- üìà –õ—É—á—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:
1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ `python main_improved.py`
2. –ù–∞–±–ª—é–¥–∞–π—Ç–µ –∑–∞ –º–µ—Ç—Ä–∏–∫–∞–º–∏
3. –°—Ä–∞–≤–Ω–∏—Ç–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
4. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–í—Å–µ —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç –≤–æ–ø—Ä–æ—Å—ã:

1. **–ü–ê–ú–Ø–¢–ö–ê.txt** - –∫—Ä–∞—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
2. **QUICK_GUIDE.md** - –±—ã—Å—Ç—Ä–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
3. **IMPROVEMENTS.md** - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
4. **SUMMARY.md** - –ø–æ–ª–Ω–æ–µ —Ä–µ–∑—é–º–µ

---

**–£–¥–∞—á–∏ —Å –æ–±—É—á–µ–Ω–∏–µ–º! üöÄ**

_Train Loss –¥–æ–ª–∂–µ–Ω –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∑–∏—Ç—å—Å—è. –ï—Å–ª–∏ –Ω–µ—Ç - —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–î–∞–ª—å–Ω–µ–π—à–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã"._
